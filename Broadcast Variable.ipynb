{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11bdeaf",
   "metadata": {},
   "source": [
    "### Broadcast variable Concepts and Exercise:\n",
    "\n",
    "\n",
    "1) Broadcast variables are read-only variables\n",
    "\n",
    "2) It is broadcasted on each machine rather than shipping a copy of the rquired dataset with tasks\n",
    "\n",
    "3) The broadcasted data is always cached in serialized form and deserialized before running the task\n",
    "\n",
    "4) We can create the broadcasted variable from a variable by calling SparkContext.broadcast(v)\n",
    "\n",
    "5) Efficiently send large, read-only value to all workers\n",
    "\n",
    "6) The broadcasted variable is saved for the use in one or more operations/iterative operations\n",
    "\n",
    "7) It is also read-only varibale/ read-only lookup table to all the nodes\n",
    "\n",
    "8) Broadcast and accumulator variable come under shared variable in spark\n",
    "\n",
    "9) Broadcast variable efficiently distribute data to tasks executing on different nodes \n",
    "\n",
    "10) But accumulator variable is to aggregate the information of the particular collections\n",
    "\n",
    "11) Spark also attempts to distribute broadcast variables using efficient broadcast algorithms to reduce communication cost.\n",
    "\n",
    "12) As we know that spark actions are trigger/executed through a set of stages, seperated by distributed \"shuffle\" operations. If the data is already broadcasted, then it automatically broadcasts the common data needed by the tasks within each stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b361b",
   "metadata": {},
   "source": [
    "### Why Broadcast variable is optimization in spark?\n",
    "\n",
    "Beacuse instead of shipping the dataframe at each operation\n",
    "it is always better to cached the small dataframe in each machine \n",
    "which is effective in terms of low i/o operation and network bandwidth.\n",
    "\n",
    "To broadcast the varibale, you don't broadcast too big table.\n",
    "It works good in terms of performance if the broadcasted dataframe is small in size.\n",
    "Decide the broadcast varibale as per the resources available. Most of the \n",
    "literatures claimed that if you have enough resources then it is always effective \n",
    "if the broadcasted data size is less than 8GB.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd0ca7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d856c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setAppName(\"my_app\").setMaster(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44f16f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95ec3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0596cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bVar = sc.broadcast([1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "143adb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bVar.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8265d2",
   "metadata": {},
   "source": [
    "##### Broadcast variables are created from a variable v by calling SparkContext.broadcast(v).\n",
    "##### The broadcast variable is a wrapper around v, and its value can be accessed by calling the value method.\n",
    "##### After broadcasted variabe is created, we can use it in any functions run on the cluster. Once the broadcast variable is created, it should not be modified so that at same spark operation, the same broadcast value is distributed in all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3f409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
